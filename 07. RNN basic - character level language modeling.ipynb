{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ('Imagine you obtained some data from a particular collection of things. \\\n",
    "It could be the heights of individuals within a group of people, the weights of cats in a clowder, \\\n",
    "the number of petals in a bouquet of flowers, and so on. Such collections are called samples \\\n",
    "and you can use the obtained data in two ways. The most straightforward thing you can do is \\\n",
    "give a detailed description of the sample. For example, you can calculate some of its useful properties. I love this article!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = list(set(sentence))\n",
    "char_dic = {c: i for i, c in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "{'o': 0, 'r': 1, 't': 2, 'q': 3, 'I': 4, 'g': 5, 's': 6, 'b': 7, 'u': 8, 'f': 9, 'c': 10, 'h': 11, ',': 12, 'e': 13, 'x': 14, 'i': 15, 'p': 16, '.': 17, 'v': 18, 'S': 19, '!': 20, 'a': 21, 'l': 22, 'm': 23, 'n': 24, 'T': 25, 'd': 26, ' ': 27, 'w': 28, 'y': 29, 'F': 30}\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence))\n",
    "print(char_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(char_dic)  # 각 char를 one-hot으로 변경 예정이므로 input_size = len(char_dic)\n",
    "hidden_state = 16\n",
    "sequence_length = 20\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i + sequence_length]\n",
    "    y_str = sentence[i + 1: i + sequence_length + 1]\n",
    "\n",
    "    x_data.append([char_dic[c] for c in x_str]) \n",
    "    y_data.append([char_dic[c] for c in y_str])\n",
    "\n",
    "x_one_hot = [np.eye(input_size)[x] for x in x_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I love this article\n",
      "[27, 4, 27, 22, 0, 18, 13, 27, 2, 11, 15, 6, 27, 21, 1, 2, 15, 10, 22, 13]\n"
     ]
    }
   ],
   "source": [
    "print(x_str)\n",
    "print([char_dic[c] for c in x_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vanilla RNN\n",
    "- $h_t = \\text{tanh}(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(CharacterRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=num_layers, nonlinearity ='tanh', batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, len(char_dic), bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs, next_state = self.rnn(x)\n",
    "        outputs = self.fc(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([460, 20, 31])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharacterRNN(input_size, hidden_state, num_layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output, next_state = nn.RNN()\n",
    "- **output** of shape `(batch, seq_len, num_directions * hidden_size)`: tensor containing the output features (`h_t`) from the last layer of the RNN for each `t`.\n",
    "    - 각 time step마다 마지막 state를 output\n",
    "- **next_state** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor containing the hidden state for `t = last time step`.\n",
    "    - multi-layer RNN, bi-directional RNN 일 경우, 여러 next state를 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, next_state = model.rnn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: torch.Size([460, 20, 16])\n",
      "next_state: torch.Size([2, 460, 16])\n"
     ]
    }
   ],
   "source": [
    "print('output:', output.shape)\n",
    "print('next_state:', next_state.shape) #two layer RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nn.CrossEntropyLoss()\n",
    "    - The `input` is expected to contain raw, **unnormalized scores for each class**.\n",
    "`input` has to be a Tensor of size `(minibatch, num_class)` \n",
    "$$\\text{loss}(x, class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      ",I,,,l,I,,,,,,,,,,,.l,,,,I,,,,,,.,,,,,,,,,,l,,,,,,,,,,ll,,,,,,,,,,,,,,,,ll,,,,,,,,I,,,I,,,l,,,I,,l,,,,l,,,,,,I,,,,,,,,,,ll,,,,ll,,,,,,,I,,,I,,,l,,,I,,l,,,,I,,,,,,,,,,,.lI,,,I,,,,,.l,,l,,,,,,I,,,,,,,,,,,ll,,l,,,,,.,,I,,,l,,,,,,,,Il,,,,,,,.l,,,,I,,,Il,,,,,l,,,,,,,I,,,l,,,,,,,,,,,I,,,I,,,,,,,.l,,,,,,,,,l,,,,v,,,,,,I,,,l,,,l,,,,,,,,l,,,,,,,,,l,l,,,,,,,,,,,I,,l,I,,,,,,,,,,l,,,l,,,,,,,,,,,,,,I,,,,,,,,,,,l,I,,,,,,I,,,,,,,,l,,l,,,,,I,,,,I,,,,,,I,,,I,,,,,,,,.l,,,,,,I,,l,I,,,,I,,,,l,,\n",
      "-----------------------------------------------------------------\n",
      "epoch: 50\n",
      "    te to  aftaln   tf e t ta o oe a panleonle  aanle taon af ahen    th oonle ao ohe th ohee of an  oe      aeleen a chon  on aaotae  the th ohee of aana on a panle    the t  e   of aaoaoe an a can el  af a oee    to  t  af  tflaeoanle taon  tf  talce  to ele  ao  toe aan a   the tf aln   thla an cheedh p  the ao   oo olohee u e   ahen  oo  aan a tan ahoe arp ta ne  th  aooeeon af ahe th ele  tne a a e e  toe aan aaleele   oo e tf ane ol     a ola teoe  thaoe  then ae eono \n",
      "-----------------------------------------------------------------\n",
      "epoch: 100\n",
      "  mecu oou cftain   dame data oromdarcarleculordcanlection of chen  . It tonl  oo ohe se ghte of on  ved ali iothen a paou  of petplec the oe mhte of oane on a poovder, the ohmaer of petale in a pouluet of profery, and yo on  Iuch callection  are called aomple, and you can ue  the cftaine  data on aho ways. The moe  ao osghtiefward chen  oou can ui an uite a petained tetcuivlion of che cample, Ior exalplec tou can dallulate oome of cni ue  tl droperteee  Itlnn  then alo oilt\n",
      "-----------------------------------------------------------------\n",
      "epoch: 150\n",
      "  mivgtyou cftained some data from a particular callection of thengs. It coul  ce ohe seights of cn sveduals iothin a droup of petple, the seights of cats in a plowder, the oumber of petals in a poupuet of plowers, and so on. Iuch collection  are called dample. and you can ued the oftained sata sn aio ways. The mos  atriightserward thing you can di is give a detailed descuiption of phe sample. Ior example, you can dalculats some of ons usertl droperties. I love thes artscnlc\n",
      "-----------------------------------------------------------------\n",
      "epoch: 200\n",
      "t livg oou cftained dome data from a particular callection of thengs. It could be the heights of in ividuals wothin a group of people, the seights of iats in a clowder, the number of petals in a couquet of flowers, and so on. Such collection  are called sample. and you can dsd the obtained data in two ways. The mos  straightsarward thing you can da ii give a detailed description of the sample. For example, you can dalculate some of its useful croperties. I love this artscuec\n",
      "-----------------------------------------------------------------\n",
      "epoch: 250\n",
      "t livg oou cbtained some data from a particular collection of thengs. It could be the heights of in ividuals wothin a group of people, the weights of iats in a clowder, the number of petals in a couquet of flowers, and so on. Such collection  are called sample. and you can usd the obtained data in two ways. The most straightsorward thing you can da is give a detailed description of the sample. For example, you can dalculate some of its useful properties. I love this artscuet\n",
      "-----------------------------------------------------------------\n",
      "epoch: 300\n",
      "t lwvg you cbtained some data from a particular collection of things. It could be the heights of in ividuals wothin a group of people, the weights of cats in a blowder, the number of petals in a bouquet of flowers, and so on. Such collection  are called samples and you can use the obtained data in two ways. The most straightforward thing you can da is give a detailed description of the sample. For example, you can calculate some of its useful properties. I love this artscle,\n",
      "-----------------------------------------------------------------\n",
      "epoch: 350\n",
      "t live you cbtained some data from a particular collection of things. It could be the heights of individuals wothin a group of people, the weights of cats in a blowder, the number of petals in a bouquet of flowers, and so on. Such collection  are called samples and you can use the obtained data in two ways. The most straightforward thing you can de is give a detailed description of the sample. For example, you can calculate some of its useful properties. I love this artscue,\n",
      "-----------------------------------------------------------------\n",
      "epoch: 400\n",
      "t mive you cbtained some data from a particular collection of things. It could be the heights of individuals within a group of people, the weights of cats in a clowder, the number of petals in a bouquet of flowers, and so on. Such collection  are called samples and you can use the obtained data in two ways. The most straightforward thing you can de is give a detailed description of the sample. For example, you can calculate some of its useful properties. I love this artscle,\n",
      "-----------------------------------------------------------------\n",
      "epoch: 450\n",
      "t mive you cbtained some data from a particular collection of thengs. It could be the heights of individuals within a group of people, the weights of cats in a clowder, the number of petals in a bouquet of flowers, and so on. Such collection  are called samples and you can use the obtained data in two ways. The most straightforward thing you can de is give a detailed description of the sample. For example, you can calculate some of its useful properties. I love this artscle,\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):    \n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs.view(-1, len(char_dic)), Y.view(-1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i%50==0:\n",
    "        results = outputs.argmax(dim=2)  # outptus.shape : [460, 20, 31] 각 time step마다 31개 중 하나 prediction\n",
    "        predict_str = \"\"\n",
    "        for j, result in enumerate(results):\n",
    "            if j == 0:\n",
    "                predict_str += ''.join([char_set[t] for t in result])  #처음 문장은 그대로 붙이고\n",
    "            else:\n",
    "                predict_str += char_set[result[-1]]  # 두번째부터는 마지막 character만 붙여가면 됨\n",
    "\n",
    "        print('epoch:',i)        \n",
    "        print(predict_str)\n",
    "        print('-----------------------------------------------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 step output을 다음 input으로 이어받아 자유롭게 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_data=[]\n",
    "init_str= 'what can I do for yo'\n",
    "init_data.append([char_dic[c] for c in x_str]) \n",
    "data = torch.FloatTensor([np.eye(input_size)[x] for x in init_data])\n",
    "\n",
    "predict_str = init_str\n",
    "next_data=None\n",
    "\n",
    "for step in range(800):\n",
    "    output = model(data) #output.shape = [1, 20, 31]\n",
    "    xx, yy = torch.max(output, dim=2)\n",
    "    results = output.argmax(dim=2) # results.shape = [1,20]\n",
    "    next_char = torch.FloatTensor(np.eye(31)[results[:,-1]]) #next_char.shape = [31]\n",
    "    next_data = data[:,1:,:] # [1, 19, 31]\n",
    "    next_data = torch.cat((next_data, next_char.view(1,1,31)), dim=1)\n",
    "    predict_str += char_set[results[:, -1]]  # 두번째부터는 마지막 character만 붙여가면 됨\n",
    "    data = next_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what can I do for yo, the weights of cats in a clowder, the number of petals in a bouquet of flowers, and so on. Such collection of things. It could be the heights of individuals within a group of people, the weights of cats in a clowder, the number of petals in a bouquet of flowers, and so on. Such collection of things. It could be the heights of individuals within a group of people, the weights of cats in a clowder, the number of petals in a bouquet of flowers, and so on. Such collection of things. It could be the heights of individuals within a group of people, the weights of cats in a clowder, the number of petals in a bouquet of flowers, and so on. Such collection of things. It could be the heights of individuals within a group of people, the weights of cats in a clowder, the number of petals in a bouque'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch] *",
   "language": "python",
   "name": "conda-env-.conda-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
