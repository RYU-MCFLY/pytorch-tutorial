{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ('Imagine you obtained some data from a particular collection of things. \\\n",
    "It could be the heights of individuals within a group of people, the weights of cats in a clowder, \\\n",
    "the number of petals in a bouquet of flowers, and so on. Such collections are called samples \\\n",
    "and you can use the obtained data in two ways. The most straightforward thing you can do is \\\n",
    "give a detailed description of the sample. For example, you can calculate some of its useful properties. I love this article!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = list(set(sentence))\n",
    "char_dic = {c: i for i, c in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "{'t': 0, 'i': 1, 'v': 2, 'd': 3, 'l': 4, 'y': 5, 'a': 6, 'w': 7, 'g': 8, '.': 9, 'x': 10, '!': 11, 'n': 12, 'F': 13, 'c': 14, ' ': 15, 'q': 16, 'T': 17, 'S': 18, 'h': 19, 'u': 20, 's': 21, 'p': 22, 'r': 23, 'I': 24, 'e': 25, 'm': 26, ',': 27, 'b': 28, 'o': 29, 'f': 30}\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence))\n",
    "print(char_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(char_dic)  # 각 char를 one-hot으로 변경 예정이므로 input_size = len(char_dic)\n",
    "hidden_state = 16\n",
    "sequence_length = 20\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i + sequence_length]\n",
    "    y_str = sentence[i + 1: i + sequence_length + 1]\n",
    "\n",
    "    x_data.append([char_dic[c] for c in x_str]) \n",
    "    y_data.append([char_dic[c] for c in y_str])\n",
    "\n",
    "x_one_hot = [np.eye(input_size)[x] for x in x_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I love this article\n",
      "[15, 24, 15, 4, 29, 2, 25, 15, 0, 19, 1, 21, 15, 6, 23, 0, 1, 14, 4, 25]\n"
     ]
    }
   ],
   "source": [
    "print(x_str)\n",
    "print([char_dic[c] for c in x_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vanilla RNN\n",
    "- $h_t = \\text{tanh}(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(CharacterRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=num_layers, nonlinearity ='tanh', batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, len(char_dic), bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs, _status = self.rnn(x)\n",
    "        outputs = self.fc(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([460, 20, 31])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharacterRNN(input_size, hidden_state, num_layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output, next_state = nn.RNN()\n",
    "- **output** of shape `(batch, seq_len, num_directions * hidden_size)`: tensor containing the output features (`h_t`) from the last layer of the RNN for each `t`.\n",
    "    - 각 time step마다 마지막 state를 output\n",
    "- **next_state** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor containing the hidden state for `t = last time step`.\n",
    "    - multi-layer RNN, bi-directional RNN 일 경우, 여러 next state를 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, next_state = model.rnn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: torch.Size([460, 20, 16])\n",
      "next_state: torch.Size([2, 460, 16])\n"
     ]
    }
   ],
   "source": [
    "print('output:', output.shape)\n",
    "print('next_state:', next_state.shape) #two layer RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nn.CrossEntropyLoss()\n",
    "    - The `input` is expected to contain raw, **unnormalized scores for each class**.\n",
    "`input` has to be a Tensor of size `(minibatch, num_class)` \n",
    "$$\\text{loss}(x, class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "niiiiinsifiiisixiinssiiisssiiisi ixss ixiifixxx iiixsssiiiisiisiiiiiiiisissiixssinsiinssniiniisiisiisiiiixixisniiiiisi i ixssiisinsnnsssiissnnsiniisiisixiisifsi inissniisisnssxxinsiiisinixnisiisi ifiixsisiisisisnsixsifiniiiiiiiixssiiixsssiiiissiiissxxxssniixinsssifiiifissxiiiissiiissiixiinssiiiisifsisssnxiiiiisssxiiissiiiiifiisiixiiniiiiisifiisxiiiiiiisifinssiinixiinsninssiiiiiiisiisiinssxxins.niiiiss.xinssnifissxiiixxixsxisss isssiiiiisiisxxxssniinsiissiisssisnsiiiisiiiisns\n",
      "-----------------------------------------------------------------\n",
      "epoch: 50\n",
      "  lhn  taf cfea n t sef  c rh t  f a c rtionler oon ertion of che  ao s  con e se the teinhii  f cni net n o tathe  arc tuc if ceinles she peinhii  f ca c onea cl ne rt the pe cer af teit   an t cef net of c  fe te sr  sercn  htit ton eiti n  ano ca   t se tles an  sof can  ae the pfea n t sera tnethencert  she pef aa ia phti neert the  aaon can   fot tine t c rainlt ser a sei n of che pe cles sen aitrcles sef can  a  n ert tef  tf cnie ne  leau f  tho   s  efe thin arthon  \n",
      "-----------------------------------------------------------------\n",
      "epoch: 100\n",
      "t l ne aou chiained dame tata t ir a particular collection of ohen s  It caulo be the teiphts of cnd nitutls tithen a p dnpeof ceinles the geights of cals in a ploneert the gamber of peia o an a porpuet of s onert, an  sorin  Iuch collection  ar  callld sarplet and sou can  se the tfiained deta on aho daya  she sor  ooroightf mdara theng you can  auis sive t tetailed dedoreption of ohe tarplet Ior ctamplet you can  allulari sofe of inh  serulecuope tios  I love then articues\n",
      "-----------------------------------------------------------------\n",
      "epoch: 150\n",
      "t linedpou chiained same data f or a particular collection of things. It could be the oeights of cndeviduals within a group of people, the geights of iats in a plowdert the gumber of peoals in a pouquet of slowers, and so in  Such collection  are called samples and you can sse the sbtained sata in tfo waya  The most otraightf mward theng you can oo is give a detailed description of thi samples Ior etample, you can salculate some of its use ul propertios  I love this articues\n",
      "-----------------------------------------------------------------\n",
      "epoch: 200\n",
      "t livesoou cbiained some data f om a particular collection of things. It could be the weights of individuals within a group of people, the neights of cats in a plowder, the number of peoals in a pouquet of flowers, and so on. Such collections are called samples and you can use the obtained data in two ways  The most straightfomward thing you can do is give a detailed description of thi sample. Ior example, you can calculate some of its userul propertios  I love this articues\n",
      "-----------------------------------------------------------------\n",
      "epoch: 250\n",
      "t l ves,ou obtained some data from a particular collection of things. It could be the weights of individuals within a group of people, the weights of cats in a clowder, the number of peoals in a pouquet of flowers, and so on. Such collections are called samples and you can use the obtained data in two ways. The most straightforward thing you can do is give a detailed description of thi sample. For example, you can calculate some of its use ul propertios  I love this articuec\n",
      "-----------------------------------------------------------------\n",
      "epoch: 300\n",
      "t l vedyou obtained some data from a particular collection of things. It could be the heights of individuals within a group of people, the weights of cats in a clowder, the number of peoals in a bouquet of flowers, and so on. Such collections are called samples and you can use the obtained data in two ways. The most straightforward thing you can do is give a detailed description of the sample. For example, you can calculate some of its useful properties. I love this articuec\n",
      "-----------------------------------------------------------------\n",
      "epoch: 350\n",
      "tml veryou obtained some data from a particular collection of things. It could be the heights of individuals within a group of people, the weights of cats in a clowder, the number of peoals in a bouquet of flowers, and so on. Such collections are called samples and you can use the obtained data in two ways. The most straightforward thing you can do is give a detailed description of the sample. For example, you can calculate some of its useful properties. I love this articuec\n",
      "-----------------------------------------------------------------\n",
      "epoch: 400\n",
      "t liveryou obtained some data from a particular collection of things. It could be the heights of individuals within a group of people, the weights of cats in a clowder, the number of petals in a bouquet of flowers, and so on. Such collections are called samples and you can use the obtained data in two ways. The most straightforward thing you can do is give a detailed description of the sample. For example, you can dalculate some of its useful properties. I love this articloc\n",
      "-----------------------------------------------------------------\n",
      "epoch: 450\n",
      "t l ve you obtained some data from a particular collection of things. It could be the heights of individuals within a group of people, the weights of cats in a clowder, the number of petals in a bouquet of flowers, and so on. Such collections are called samples and you can use the obtained data in two ways. The most straightforward thing you can do is give a detailed description of the sample. For example, you can calculate some of its useful properties. I love this articlec\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):    \n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs.view(-1, len(char_dic)), Y.view(-1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i%50==0:\n",
    "        results = outputs.argmax(dim=2)  # outptus.shape : [460, 20, 31] 각 time step마다 31개 중 하나 prediction\n",
    "        predict_str = \"\"\n",
    "        for j, result in enumerate(results):\n",
    "            if j == 0:\n",
    "                predict_str += ''.join([char_set[t] for t in result])  #처음 문장은 그대로 붙이고\n",
    "            else:\n",
    "                predict_str += char_set[result[-1]]  # 두번째부터는 마지막 character만 붙여가면 됨\n",
    "\n",
    "        print('epoch:',i)        \n",
    "        print(predict_str)\n",
    "        print('-----------------------------------------------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 step output을 다음 input으로 이어받아 자유롭게 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_data=[]\n",
    "init_str= 'what can I do for yo'\n",
    "init_data.append([char_dic[c] for c in x_str]) \n",
    "data = torch.FloatTensor([np.eye(input_size)[x] for x in init_data])\n",
    "\n",
    "predict_str = init_str\n",
    "next_data=None\n",
    "\n",
    "for step in range(800):\n",
    "    output = model(data) #output.shape = [1, 20, 31]\n",
    "    xx, yy = torch.max(output, dim=2)\n",
    "    results = output.argmax(dim=2) # results.shape = [1,20]\n",
    "    next_char = torch.FloatTensor(np.eye(31)[results[:,-1]]) #next_char.shape = [31]\n",
    "    next_data = data[:,1:,:] # [1, 19, 31]\n",
    "    next_data = torch.cat((next_data, next_char.view(1,1,31)), dim=1)\n",
    "    predict_str += char_set[results[:, -1]]  # 두번째부터는 마지막 character만 붙여가면 됨\n",
    "    data = next_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what can I do for yoctions are called samples and you can use the obtained data in two ways. The most straightforward thing you can do is give a detailed description of the sample. For example, you can calculate some of its useful properties. I love this articlos. you obtained some data from a particular collection of things. It could be the heights of individuals within a group of people, the weights of cats in a clowder, the number of petals in a bouquet of flowers, and so on. Such collections are called samples and you can use the obtained data in two ways. The most straightforward thing you can do is give a detailed description of the sample. For example, you can calculate some of its useful properties. I love this articlos. you obtained some data from a particular collection of things. It could be the he'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch] *",
   "language": "python",
   "name": "conda-env-.conda-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
