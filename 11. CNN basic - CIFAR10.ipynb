{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "cifar_train = datasets.CIFAR10(root='CIFAR10_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "cifar_test = datasets.CIFAR10(root='CIFAR10_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 15\n",
    "batch_size = 128\n",
    "\n",
    "valid_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(cifar_train)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split = int(np.floor(valid_ratio * num_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SubsetRandomSampler(indices)\n",
    "    - Samples elements randomly from a given list of indices, without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=cifar_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          sampler=train_sampler,\n",
    "                                          drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=cifar_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          sampler=valid_sampler,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vaild_loss(model_valid):\n",
    "    avg_loss = 0\n",
    "    with torch.no_grad():\n",
    "        model_valid.eval()\n",
    "        for images, labels in valid_loader:\n",
    "            pred = model_valid(images.to(device))\n",
    "            criterion = nn.CrossEntropyLoss().to(device)\n",
    "            loss = criterion(pred, labels.to(device))\n",
    "            avg_loss+= loss.item()\n",
    "    \n",
    "    return avg_loss / len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$          H,W_{out} = \\left\\lfloor\\frac{H,W_{in}  + 2 \\times \\text{padding} - \\text{dilation}\n",
    "                    \\times (\\text{kernel_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 마지막에 fc 연결하기 전에 test tensor 넣고 out.shape 찍어보기. 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNN_test(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BasicCNN_test, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "        print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicCNN_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 15, 15])\n",
      "torch.Size([1, 64, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "xx = torch.Tensor(1,3,32,32) # torch는 [channel, H, W]\n",
    "out = model(xx)  \n",
    "# fc는 64x6x6를 input으로 받아야 겠군."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        self.fc = nn.Linear(128*6*6, 10, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.shape[0], -1) # out.shape[0] : batch_size\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, train loss:1.59295, valid loss:1.42352\n",
      "Epoch:1, train loss:1.26292, valid loss:1.26442\n",
      "Epoch:2, train loss:1.12640, valid loss:1.12634\n",
      "Epoch:3, train loss:1.04102, valid loss:1.05506\n",
      "Epoch:4, train loss:0.98192, valid loss:1.02855\n",
      "Epoch:5, train loss:0.93482, valid loss:0.99353\n",
      "Epoch:6, train loss:0.89247, valid loss:1.00706\n",
      "Epoch:7, train loss:0.85487, valid loss:0.96809\n",
      "Epoch:8, train loss:0.83248, valid loss:0.95905\n",
      "Epoch:9, train loss:0.80385, valid loss:0.93662\n",
      "Epoch:10, train loss:0.77483, valid loss:0.94027\n",
      "Epoch:11, train loss:0.75683, valid loss:0.92156\n",
      "Epoch:12, train loss:0.73483, valid loss:0.93454\n",
      "Epoch:13, train loss:0.71832, valid loss:0.92920\n",
      "Epoch:14, train loss:0.69110, valid loss:0.96157\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "total_batch = len(train_loader)\n",
    "model.train()\n",
    "best_valid = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = 0\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        X = X.to(device) #img\n",
    "        Y = Y.to(device) #label\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss / total_batch\n",
    "    \n",
    "    loss_valid = vaild_loss(model)\n",
    "    print('Epoch:{}, train loss:{:.5f}, valid loss:{:.5f}'.format(epoch, avg_loss, loss_valid))\n",
    "\n",
    "    if loss_valid < best_valid:\n",
    "        torch.save(model.state_dict(), './saves/models/basicCNN.pth')\n",
    "        best_valid = loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=cifar_test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test images with BasicCNN: 0.6941\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model_test = BasicCNN().to(device)\n",
    "model_test.load_state_dict(torch.load('./saves/models/basicCNN.pth'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_test.eval()\n",
    "    for images, labels in test_loader:\n",
    "        output = model_test(images.to(device))\n",
    "        _, predicted = torch.max(output, dim=1)        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels.to(device)).sum().item()\n",
    "\n",
    "print('Accuracy on test images with BasicCNN:', (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Batchnorm(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN_Batchnorm, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128*5*5, 128, bias=True),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 10, bias=True))\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.shape[0],-1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Batchnorm().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, train loss:1.16244, valid loss:0.98175\n",
      "Epoch:1, train loss:0.89215, valid loss:0.91366\n",
      "Epoch:2, train loss:0.75818, valid loss:0.79455\n",
      "Epoch:3, train loss:0.66787, valid loss:0.75104\n",
      "Epoch:4, train loss:0.60049, valid loss:0.76877\n",
      "Epoch:5, train loss:0.55054, valid loss:0.73790\n",
      "Epoch:6, train loss:0.49906, valid loss:0.75485\n",
      "Epoch:7, train loss:0.46275, valid loss:0.81312\n",
      "Epoch:8, train loss:0.41925, valid loss:0.82009\n",
      "Epoch:9, train loss:0.39304, valid loss:0.88460\n",
      "Epoch:10, train loss:0.35816, valid loss:0.90321\n",
      "Epoch:11, train loss:0.32785, valid loss:0.90632\n",
      "Epoch:12, train loss:0.29952, valid loss:0.95983\n",
      "Epoch:13, train loss:0.27413, valid loss:1.02390\n",
      "Epoch:14, train loss:0.25732, valid loss:0.95564\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_loader)\n",
    "model.train()\n",
    "best_valid = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = 0\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        X = X.to(device) #img\n",
    "        Y = Y.to(device) #label\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss / total_batch\n",
    "\n",
    "    loss_valid = vaild_loss(model)\n",
    "    print('Epoch:{}, train loss:{:.5f}, valid loss:{:.5f}'.format(epoch, avg_loss, loss_valid))\n",
    "\n",
    "    if loss_valid < best_valid:\n",
    "        torch.save(model.state_dict(), './saves/models/CNN_Batchnorm.pth')\n",
    "        best_valid = loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test images with Batchnorm CNN: 0.7624\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model_test = CNN_Batchnorm().to(device)\n",
    "model_test.load_state_dict(torch.load('./saves/models/CNN_Batchnorm.pth'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_test.eval()\n",
    "    for images, labels in test_loader:\n",
    "        output = model_test(images.to(device))\n",
    "        _, predicted = torch.max(output, dim=1)        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels.to(device)).sum().item()\n",
    "\n",
    "print('Accuracy on test images with Batchnorm CNN:', (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch] *",
   "language": "python",
   "name": "conda-env-.conda-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
