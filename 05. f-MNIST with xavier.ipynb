{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive fMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 15\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataset 로드할 때 transform.ToTensor() \n",
    "    - Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = datasets.FashionMNIST(root='fMNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = datasets.FashionMNIST(root='fMNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_data example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = mnist_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: torch.Size([1, 28, 28])\n",
      "label: 9\n"
     ]
    }
   ],
   "source": [
    "print('image:', image.shape)\n",
    "print('label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NaiveModel, self).__init__()\n",
    "        self.dense1 = nn.Linear(784,256)\n",
    "        self.dense2 = nn.Linear(256,256)\n",
    "        self.dense3 = nn.Linear(256,10)\n",
    "        self.relu = F.relu\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.relu(self.dense1(x))\n",
    "        output = self.relu(self.dense2(output))\n",
    "        output = self.dense3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveModel().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model parameters에 access하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 784])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(model.dense1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(model.dense1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 784])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for item in model.dense1.parameters():\n",
    "    print(np.shape(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 784])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256])\n",
      "torch.Size([256])\n",
      "torch.Size([10, 256])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for item in model.parameters():\n",
    "    print(np.shape(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normal init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in model.parameters():\n",
    "    nn.init.normal_(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss:  178.77813720703125\n",
      "epoch: 1 loss:  70.01497650146484\n",
      "epoch: 2 loss:  50.85539245605469\n",
      "epoch: 3 loss:  40.01912307739258\n",
      "epoch: 4 loss:  32.85101318359375\n",
      "epoch: 5 loss:  27.57170295715332\n",
      "epoch: 6 loss:  23.160036087036133\n",
      "epoch: 7 loss:  20.083572387695312\n",
      "epoch: 8 loss:  17.494884490966797\n",
      "epoch: 9 loss:  15.129667282104492\n",
      "epoch: 10 loss:  13.448171615600586\n",
      "epoch: 11 loss:  11.841980934143066\n",
      "epoch: 12 loss:  10.589550971984863\n",
      "epoch: 13 loss:  9.266057014465332\n",
      "epoch: 14 loss:  8.550172805786133\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)  #60,000/128 = 468\n",
    "for epoch in range(epochs):    \n",
    "    avg_loss = 0\n",
    "    for X_batch, Y_batch in data_loader:\n",
    "        X_batch = torch.reshape(X_batch, [-1, 784]).to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "        \n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, Y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss\n",
    "    avg_loss /= total_batch\n",
    "    print('epoch:', epoch, 'loss: ', avg_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test_data example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = mnist_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-417.1286, -992.2338, -539.6521, -672.2505, -155.7197,  827.4575,\n",
      "         -199.6065,  862.0845,  207.2610, 1172.1598]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = model(image.view(-1,784).to(device))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1172.1598], device='cuda:0', grad_fn=<MaxBackward0>)\n",
      "tensor([9], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "max_val, argmax_val = torch.max(output, dim=1)  # max, argmax 둘다 return\n",
    "print(max_val)\n",
    "print(argmax_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(argmax_val==label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test images: 0.823\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        output = model(images.view(-1,784).to(device))\n",
    "        _, predicted = torch.max(output, dim=1)        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels.to(device)).sum().item()\n",
    "\n",
    "print('Accuracy on test images:', (correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- note. 위와 같은 모델로 MNIST 돌렸을 때 test accuracy 94% 나왔음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Other initialization: Xavier for tanh, He for relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- He initialization: we just multiply random norm initialization with $\\sqrt{\\frac{2}{size^{[l-1]}}}$\n",
    "- $W^{l}$ =  np.random.randn(size_l, size_l-1) * np.sqrt(2/size_l-1)\n",
    "- Xavier initialization: mutiply with $\\sqrt{\\frac{1}{size^{[l-1]}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래와 같이 하면 error 뜸. \n",
    "- Fan in and fan out can not be computed for tensor with fewer than 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for params in model.parameters():\n",
    "#     nn.init.xavier_uniform_(params)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xavier = NaiveModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0530,  0.0202,  0.0023,  ...,  0.0925, -0.0421, -0.1132],\n",
       "        [-0.0084, -0.0689,  0.0030,  ..., -0.0637,  0.1469, -0.0965],\n",
       "        [-0.1422,  0.0940,  0.1371,  ...,  0.0112, -0.1289,  0.1424],\n",
       "        ...,\n",
       "        [ 0.0405,  0.0858, -0.0344,  ...,  0.0395, -0.1401,  0.0501],\n",
       "        [ 0.0062, -0.1438,  0.0675,  ...,  0.0591,  0.0258,  0.1370],\n",
       "        [ 0.1383,  0.1414, -0.0412,  ...,  0.0933,  0.1319,  0.0420]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.xavier_uniform_(model_xavier.dense1.weight)\n",
    "nn.init.xavier_uniform_(model_xavier.dense2.weight)\n",
    "nn.init.xavier_uniform_(model_xavier.dense3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model_xavier.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss:  0.5027369856834412\n",
      "epoch: 1 loss:  0.3580172061920166\n",
      "epoch: 2 loss:  0.3243653178215027\n",
      "epoch: 3 loss:  0.29909634590148926\n",
      "epoch: 4 loss:  0.28359007835388184\n",
      "epoch: 5 loss:  0.26590773463249207\n",
      "epoch: 6 loss:  0.2530584931373596\n",
      "epoch: 7 loss:  0.23926635086536407\n",
      "epoch: 8 loss:  0.22942577302455902\n",
      "epoch: 9 loss:  0.222588449716568\n",
      "epoch: 10 loss:  0.2129589468240738\n",
      "epoch: 11 loss:  0.20299723744392395\n",
      "epoch: 12 loss:  0.1939186453819275\n",
      "epoch: 13 loss:  0.18669550120830536\n",
      "epoch: 14 loss:  0.1814003437757492\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)  #60,000/128 = 468\n",
    "for epoch in range(epochs):    \n",
    "    avg_loss = 0\n",
    "    for X_batch, Y_batch in data_loader:\n",
    "        X_batch = torch.reshape(X_batch, [-1, 784]).to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "        \n",
    "        pred = model_xavier(X_batch)\n",
    "        loss = criterion(pred, Y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss\n",
    "    avg_loss /= total_batch\n",
    "    print('epoch:', epoch, 'loss: ', avg_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test images with Xavier initialization: 0.8923\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        output = model_xavier(images.view(-1,784).to(device))\n",
    "        _, predicted = torch.max(output, dim=1)        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels.to(device)).sum().item()\n",
    "\n",
    "print('Accuracy on test images with Xavier initialization:', (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch] *",
   "language": "python",
   "name": "conda-env-.conda-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
